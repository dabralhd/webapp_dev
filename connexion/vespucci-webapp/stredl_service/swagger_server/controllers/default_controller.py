import connexion
import six

from swagger_server.models.cube_ai_analyze_result import CubeAIAnalyzeResult  # noqa: E501
from swagger_server.models.cube_ai_error import CubeAIError  # noqa: E501
from swagger_server.models.cube_ai_generate_result import CubeAIGenerateResult  # noqa: E501
from swagger_server.models.cube_ai_validate_result import CubeAIValidateResult  # noqa: E501
from swagger_server import util


def analyze(deep_learning_model=None, quantize=None, allocate_inputs=None, allocate_outputs=None, compression=None, name=None, split_weights=None):  # noqa: E501
    """Analyze Input Model

    The &#x27;analyze&#x27; command is the primary command to import, to parse, to check and to render an uploaded model. Detailed report provides the main system metrics to know if the generated code can be deployed on a STREDL device. After completion, the user can be fully confident on the imported model in term of supported layer/operators. # noqa: E501

    :param deep_learning_model: 
    :type deep_learning_model: strstr
    :param quantize: 
    :type quantize: strstr
    :param allocate_inputs: If defined, this flag indicates that the &#x27;activations&#x27; buffer will be also used to handle the input buffers else, default behavior, they should be allocated separately in the user memory space. Depending on the size of the input data, the &#x27;activations&#x27; buffer may be bigger but overall less than the sum of the activation buffer plus the input buffer.
    :type allocate_inputs: bool
    :param allocate_outputs: If defined, this flag indicates that the &#x27;activations&#x27; buffer will be also used to handle the outputs buffers else, default behavior, they should be allocated separately in the user memory space. Depending on the size of the output data, the &#x27;activations&#x27; buffer may be bigger but overall less than the sum of the activation buffer plus the output buffer.
    :type allocate_outputs: bool
    :param compression: Indicates the expected global factor of compression which will be applied (default &#x27;1&#x27;). Compression can be only performed on the dense-type layer.
    :type compression: int
    :param name: indicates the C-name (C-string type) of the imported model. Used to prefix the name of specialized C-files and API functions. Also used for the temporary files, this allows to use the same workspace/output directories for different models (default &#x27;network&#x27;).
    :type name: str
    :param split_weights: If defined, this flag indicates that one C-array is generated by weights/bias data tensor instead to have an unique C-array (&#x27;weights&#x27; buffer) for the whole.
    :type split_weights: bool

    :rtype: CubeAIAnalyzeResult
    """
    return 'do some magic!'


def generate(deep_learning_model=None, quantize=None, address=None, allocate_inputs=None, allocate_outputs=None, binary=None, compression=None, copy_weights_at=None, full_binary_uuid=None, generate_fota=None, name=None, split_weights=None, generate_full_binary=None, return_full_binary_only=None):  # noqa: E501
    """Generate Input Model

    The &#x27;generate&#x27; command is used to generate the specialized network and data C-files. # noqa: E501

    :param deep_learning_model: 
    :type deep_learning_model: strstr
    :param quantize: 
    :type quantize: strstr
    :param address: With &#x27;binary&#x27; flag, this helper option can be used to indicate the address where the weights will be located to generate a particular &#x27;_data.c&#x27; file.
    :type address: str
    :param allocate_inputs: If defined, this flag indicates that the &#x27;activations&#x27; buffer will be also used to handle the input buffers else, default behavior, they should be allocated separately in the user memory space. Depending on the size of the input data, the &#x27;activations&#x27; buffer may be bigger but overall less than the sum of the activation buffer plus the input buffer.
    :type allocate_inputs: bool
    :param allocate_outputs: If defined, this flag indicates that the &#x27;activations&#x27; buffer will be also used to handle the outputs buffers else, default behavior, they should be allocated separately in the user memory space. Depending on the size of the output data, the &#x27;activations&#x27; buffer may be bigger but overall less than the sum of the activation buffer plus the output buffer.
    :type allocate_outputs: bool
    :param binary: If defined, this flag forces the generation of a binary file _data.bin instead _data.c and _data.h files. It contains only the weights of the model, C-implementation of the topology is always generated in the .c/.h files.
    :type binary: bool
    :param compression: Indicates the expected global factor of compression which will be applied (default &#x27;1&#x27;). Compression can be only performed on the dense-type layer.
    :type compression: int
    :param copy_weights_at: With &#x27;binary&#x27; flag and &#x27;address&#x27; option, this helper option can be used to indicate the destination address where the weights should be copied at initialization time thanks to a particular &#x27;_data.c&#x27; file.
    :type copy_weights_at: str
    :param full_binary_uuid: If defined and combined with the generate_full_binary parameter set to True, this parameter specifies a unique UUID that is embedded into the generated binary that can be used to track its identity.
    :type full_binary_uuid: 
    :param generate_fota: If the &#x27;binary&#x27; flag is passed, this additional argument with True value allows to add a specific ST header which is expected for a partial Firmware Over-The-Air (FOTA) process. Name of the generated file is suffixed with the _fota extension _data_fota.bin.
    :type generate_fota: bool
    :param name: indicates the C-name (C-string type) of the imported model. Used to prefix the name of specialized C-files and API functions. Also used for the temporary files, this allows to use the same workspace/output directories for different models (default &#x27;network&#x27;).
    :type name: str
    :param split_weights: If defined, this flag indicates that one C-array is generated by weights/bias data tensor instead to have an unique C-array (&#x27;weights&#x27; buffer) for the whole.
    :type split_weights: bool
    :param generate_full_binary: If defined, this flag requires to generate a full binary (not network weights only). Currently the API supports only OpenMV builds.
    :type generate_full_binary: bool
    :param return_full_binary_only: If defined and combined with the generate_full_binary parameter set to True, this flag tells the service to return a response containing only the generated full binary.
    :type return_full_binary_only: bool

    :rtype: CubeAIGenerateResult
    """
    return 'do some magic!'


def validate(deep_learning_model=None, quantize=None, valinput=None, valoutput=None, allocate_inputs=None, allocate_outputs=None, batches=None, classifier=None, compression=None, name=None, split_weights=None, validate_batch_mode=None):  # noqa: E501
    """Validate Input Model

    The &#x27;validate&#x27; command allows to import, to render and to validate the generated C-files (currently supports only desktop mode). # noqa: E501

    :param deep_learning_model: 
    :type deep_learning_model: strstr
    :param quantize: 
    :type quantize: strstr
    :param valinput: 
    :type valinput: strstr
    :param valoutput: 
    :type valoutput: strstr
    :param allocate_inputs: If defined, this flag indicates that the &#x27;activations&#x27; buffer will be also used to handle the input buffers else, default behavior, they should be allocated separately in the user memory space. Depending on the size of the input data, the &#x27;activations&#x27; buffer may be bigger but overall less than the sum of the activation buffer plus the input buffer.
    :type allocate_inputs: bool
    :param allocate_outputs: If defined, this flag indicates that the &#x27;activations&#x27; buffer will be also used to handle the outputs buffers else, default behavior, they should be allocated separately in the user memory space. Depending on the size of the output data, the &#x27;activations&#x27; buffer may be bigger but overall less than the sum of the activation buffer plus the output buffer.
    :type allocate_outputs: bool
    :param batches: 
    :type batches: int
    :param classifier: If defined, this flag that the provided model should be considered as a classifier vs regressor. This implies that the computation of the &#x27;CM&#x27; and &#x27;ACC&#x27; metrics will be evaluated, else an auto-detection mechanism is used to evaluate if the model is a classifier or not.
    :type classifier: bool
    :param compression: Indicates the expected global factor of compression which will be applied (default &#x27;1&#x27;). Compression can be only performed on the dense-type layer.
    :type compression: int
    :param name: indicates the C-name (C-string type) of the imported model. Used to prefix the name of specialized C-files and API functions. Also used for the temporary files, this allows to use the same workspace/output directories for different models (default &#x27;network&#x27;).
    :type name: str
    :param split_weights: If defined, this flag indicates that one C-array is generated by weights/bias data tensor instead to have an unique C-array (&#x27;weights&#x27; buffer) for the whole.
    :type split_weights: bool
    :param validate_batch_mode: when a custom data set input is used, this parameter is used to limit the number of samples. Two modes are available, &#x27;first&#x27; to indicate that only the first &#x27;batches&#x27; samples are used, &#x27;random&#x27; indicates that &#x27;batches&#x27; samples are randomly selected with a fixed seed.
    :type validate_batch_mode: str

    :rtype: CubeAIValidateResult
    """
    return 'do some magic!'
